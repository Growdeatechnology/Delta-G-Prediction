{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a168e30a-3c14-42d7-a668-b45fbbfdde61",
   "metadata": {},
   "source": [
    "load all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a099f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:02:56.669473: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9498] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-24 16:02:56.669512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-24 16:02:56.671264: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-24 16:02:56.768543: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 16:02:57.564256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gdt-ws4/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/gdt-ws4/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:02:58.744484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:02:58.828241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:02:58.828386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth to True\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2258cb10-df1b-4ab5-aad6-40c0588db3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from proteinbert import load_pretrained_model\n",
    "# from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d616c-7222-41e2-8129-14248c2ee02d",
   "metadata": {},
   "source": [
    "load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45636e-6f0b-4daf-87ea-cb670a437bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mutated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9596321-1a0e-4298-8ed0-eea9fd009686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load ProteinBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "\n",
    "# Protein sequence\n",
    "protein_sequence = \"MSIFLCFLLLLPLSLIFLKKLLPSKGKLPPGPKGLPIIGNLHQFGRFLHKSLHKISQEYGPVMLLHFGVVPVIIVSSKEGAEEVLKTHDLETCSRPKTVGSGLFTYNFKDIGFAPYGENWREMRKIAVSELFSQKKLKSFRYIREDESQLLVRKVSKSALETPTSSVNLRKVIFTFAASIICRLSFGQNFCDFVDMETVEELVLESETNLGSLAFADFLPAGWIIDRISGQHSTVMKAFSKLTNFFELVIDDHLKSGKIEDHSDIISVMLDMINKPTEVGSYKVTDDHLKGLMSDVFLAGVNAGSITMIWTMTELSRHPRVMRKLQEEIRAALGPNKEKITEEDLEKVEYLKMVIEEAFRLHPPAPLLLPRLTMSDINIQGYSIPKNTMIQINTYTIGRDPKNWTKPDEFIPERFVDNPIEYKGQHFELLPFGAGRRVCPGMATGITIVELGLLSLLYFFDWSLPNGMTTKDIDMEEDGAFVIAKKVSLELVPTLHRW\"\n",
    "\n",
    "# Encode the protein sequence\n",
    "tokens = tokenizer.encode(protein_sequence, add_special_tokens=True)\n",
    "input_ids = torch.tensor(tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "encoded_sequence = outputs.last_hidden_state  # Use the last hidden state as the encoded representation\n",
    "\n",
    "# Print the shape of the encoded sequence\n",
    "print(\"Encoded Sequence Shape:\", encoded_sequence.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de4df1-2aeb-4df2-988c-1a6894c8f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e6a6d-20ae-42cd-845f-a58bfd739d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_protein_sequences(protein_sequence):\n",
    "    tokens = tokenizer.encode(protein_sequence, add_special_tokens=True)\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    encoded_sequence = outputs.last_hidden_state  # Use the last hidden state as the encoded representation\n",
    "    return encoded_sequence\n",
    "\n",
    "protein_sequences = df['mutated_sequence']\n",
    "encoded_sequences = [encode_protein_sequences(seq) for seq in protein_sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540955d-a4b2-441f-b4e5-8d433b40e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences_array = np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4828e32-a207-4b6a-8d1e-6ac218ed1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6d749-030f-4add-a8f4-a8b87f1a94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for i in encoded_sequences_array:\n",
    "    new.append(np.array(i.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561a829-224f-41f4-8431-bfe691057334",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= new[0]==new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c254ecf-feb0-4560-b863-726a4bf9ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e730f9-8ec8-48a6-ad7d-5f14e3df9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = df['delta_G']\n",
    "new_y = np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ad6d0-d4b3-4372-ad1f-6be14a09854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(new, new_y, test_size=0.2)\n",
    "\n",
    "# Initialize and train a Random Forest regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=10000)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f1217-582e-4ef2-bec4-ba19a8debb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(new, new_y, test_size=0.1)\n",
    "\n",
    "# Initialize and train various regression models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=10),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Regression\": SVR()\n",
    "}\n",
    "\n",
    "results = {}  # To store the evaluation results for each model\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[model_name] = {\"MSE\": mse, \"R2\": r2}\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(model_name)\n",
    "    print(\"Mean Squared Error:\", metrics[\"MSE\"])\n",
    "    print(\"R-squared (R2) Score:\", metrics[\"R2\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fa334-8b2e-44b5-9eab-d5e87eba93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2e571-4636-47a1-a1d8-d1f84303d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the protein sequences\n",
    "sequences = df['mutated_sequence']\n",
    "\n",
    "combined_features = []\n",
    "\n",
    "# Loop through each sequence\n",
    "for sequence in sequences:\n",
    "    # Calculate AAC\n",
    "    protein_analysis = ProteinAnalysis(sequence)\n",
    "    aac = list(protein_analysis.get_amino_acids_percent().values())\n",
    "\n",
    "    # Calculate PSSM as simple counts\n",
    "    pssm = [sequence.count(aa) for aa in \"ARNDCQEGHILKMFPSTWYV\"]\n",
    "\n",
    "    # Combine AAC and PSSM features for each sequence\n",
    "    combined = aac + pssm\n",
    "    combined_features.append(combined)\n",
    "\n",
    "# Convert features list to NumPy array\n",
    "combined_array = np.array(combined_features)\n",
    "\n",
    "# # Define column names\n",
    "# aac_columns = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "# pssm_columns = [\"PSSM_\" + aa for aa in \"ARNDCQEGHILKMFPSTWYV\"]\n",
    "# combined_columns = aac_columns + pssm_columns\n",
    "\n",
    "# # Create a DataFrame with combined features\n",
    "# combined_df = pd.DataFrame(combined_array, columns=combined_columns)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc00e7-ca5c-4a45-87da-c737e70e9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbe9d1-8dd8-44ff-b216-604f94f3813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373345d-7650-4ce4-b1b5-8013cf1bab8e",
   "metadata": {},
   "source": [
    "Encode the protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d73c4b2-2d58-48da-aaa8-070c01a7d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "protein_sequences = df['mutated_sequence']\n",
    "delta_g_values = df['delta_G']\n",
    "\n",
    "# Define the amino acids and their order\n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    # Create a dictionary to map each amino acid to an index\n",
    "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "    \n",
    "    # Initialize an array of zeros with the shape (sequence_length, number_of_amino_acids)\n",
    "    sequence_length = len(sequence)\n",
    "    one_hot_encoded = np.zeros((sequence_length, len(amino_acids)), dtype=int)\n",
    "    \n",
    "    # Set the appropriate index to 1 for each amino acid in the sequence\n",
    "    for i, aa in enumerate(sequence):\n",
    "        one_hot_encoded[i, aa_to_index[aa]] = 1\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "# One-hot encode all the protein sequences in the DataFrame\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming you have a list of one-hot encoded sequences\n",
    "encoded_sequences = [one_hot_encode_sequence(seq) for seq in protein_sequences]\n",
    "\n",
    "#Find the maximum sequence length\n",
    "max_sequence_length = max(len(seq) for seq in encoded_sequences)\n",
    "\n",
    "# Pad sequences to the maximum length\n",
    "padded_sequences = pad_sequences(encoded_sequences, maxlen=max_sequence_length, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "# Convert the padded_sequences list to a numpy array\n",
    "X = np.array(padded_sequences)\n",
    "\n",
    "# Convert the delta_g_values to a numpy array\n",
    "y = np.array(delta_g_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fad182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to add random noise to one-hot encoded vectors\n",
    "def add_noise(data, noise_level=0.05):\n",
    "    noisy_data = data + noise_level * np.random.random(data.shape)\n",
    "    noisy_data = np.clip(noisy_data, 0, 1)  # Clip values to [0, 1] range\n",
    "    return noisy_data\n",
    "\n",
    "# Augment the data with noise\n",
    "augmented_data = np.array([add_noise(sample) for sample in X])\n",
    "\n",
    "# Print some examples of the augmented data\n",
    "# for i, augmented_sample in enumerate(augmented_data):\n",
    "#     print(f\"Augmented Sample {i+1}:\\n{augmented_sample}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_500 = augmented_data[0:500]\n",
    "# aug_1000 = augmented_data[500:1000]\n",
    "# aug_1500 = augmented_data[1000:1500]\n",
    "# aug_2000 = augmented_data[1500:2000]\n",
    "# aug_2100 = augmented_data[2000:2100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be287fd7-d5b4-4cc4-9576-7470babd9bbd",
   "metadata": {},
   "source": [
    "split the X,y value in train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c33b704-fb55-477a-8075-12967dba1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes: (1469, 34350, 20) (1469,)\n",
      "Validation data shapes: (207, 34350, 20) (207,)\n",
      "Test data shapes: (423, 34350, 20) (423,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 70% training and 30% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "\n",
    "# # Split the remaining data (30%) into 10% validation and 20% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "# # Print the shapes of the datasets\n",
    "print(\"Training data shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shapes:\", X_val.shape, y_val.shape)\n",
    "print(\"Test data shapes:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78604f-199f-4923-867f-6a3fb22d8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.67,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbba87-4fa8-4871-80e1-5064b2d500db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:03:19.241496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.241655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.241757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.326342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.326474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.326585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 16:03:19.326663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1898] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10093 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-08-24 16:03:19.773608: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2690292000 exceeds 10% of free system memory.\n",
      "2023-08-24 16:03:21.859436: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2690292000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:03:23.473326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-08-24 16:03:24.837837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10a201f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-24 16:03:24.837855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-24 16:03:24.843845: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-24 16:03:24.912561: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 21.7190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:03:30.345247: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1346520000 exceeds 10% of free system memory.\n",
      "2023-08-24 16:03:31.740457: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1346520000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 11s 256ms/step - loss: 21.7190 - val_loss: 27.9589 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 15.1863 - val_loss: 13.3038 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 13.5539 - val_loss: 13.2406 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 11.9022 - val_loss: 10.0463 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 9.8162 - val_loss: 10.2635 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 8.4421 - val_loss: 8.4828 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 8.2819 - val_loss: 8.7845 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 7.1264 - val_loss: 8.4749 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 6.2619 - val_loss: 8.9863 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 5.6987 - val_loss: 23.4665 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 18.0110 - val_loss: 10.9132 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 9.7729 - val_loss: 9.5692 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 6.7361\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 6.7361 - val_loss: 10.4189 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 6.7627 - val_loss: 8.5759 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 5.7784 - val_loss: 8.3394 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 4.7126 - val_loss: 8.9279 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 4.5475 - val_loss: 7.8789 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.9288 - val_loss: 7.8958 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 4.1261 - val_loss: 7.9699 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.6338 - val_loss: 8.2001 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.2707 - val_loss: 7.8740 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.3537 - val_loss: 7.9754 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.4909 - val_loss: 8.2301 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 3.0341 - val_loss: 7.8977 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.7344 - val_loss: 7.7215 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 2.6325 - val_loss: 8.0079 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 2.5124 - val_loss: 7.9049 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 2.6712 - val_loss: 7.7137 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.4986 - val_loss: 7.7080 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.6941 - val_loss: 7.8682 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 3s 113ms/step - loss: 2.3970 - val_loss: 7.9481 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.4557 - val_loss: 7.9214 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.4175 - val_loss: 7.9651 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.3991 - val_loss: 7.6568 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1993 - val_loss: 7.9910 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2756 - val_loss: 7.6622 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2630 - val_loss: 7.8223 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.4141 - val_loss: 7.7485 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.3860\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.3860 - val_loss: 7.9664 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.6577 - val_loss: 7.7918 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1601 - val_loss: 7.7865 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2549 - val_loss: 7.8314 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2266 - val_loss: 7.7776 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.2522\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2522 - val_loss: 7.7383 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.1420 - val_loss: 7.7437 - lr: 1.2500e-04\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 3s 113ms/step - loss: 2.1709 - val_loss: 7.6883 - lr: 1.2500e-04\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 3s 113ms/step - loss: 2.0324 - val_loss: 7.7870 - lr: 1.2500e-04\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1777 - val_loss: 7.6931 - lr: 1.2500e-04\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.1252\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.1252 - val_loss: 7.6616 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 1.9687 - val_loss: 7.6909 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0556 - val_loss: 7.6739 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0959 - val_loss: 7.7292 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0080 - val_loss: 7.7656 - lr: 6.2500e-05\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0503\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0503 - val_loss: 7.7201 - lr: 6.2500e-05\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9599 - val_loss: 7.7336 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0640 - val_loss: 7.7118 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0475 - val_loss: 7.7430 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.3196 - val_loss: 7.6852 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.1784\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1784 - val_loss: 7.7134 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 1.9954 - val_loss: 7.7124 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9578 - val_loss: 7.7365 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0208 - val_loss: 7.7387 - lr: 1.5625e-05\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 3s 113ms/step - loss: 1.9523 - val_loss: 7.7264 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.9717\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 1.9717 - val_loss: 7.7227 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9300 - val_loss: 7.7341 - lr: 7.8125e-06\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0441 - val_loss: 7.7451 - lr: 7.8125e-06\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0690 - val_loss: 7.7430 - lr: 7.8125e-06\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0317 - val_loss: 7.7451 - lr: 7.8125e-06\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0708\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0708 - val_loss: 7.7521 - lr: 7.8125e-06\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0975 - val_loss: 7.7430 - lr: 3.9063e-06\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9228 - val_loss: 7.7374 - lr: 3.9063e-06\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0078 - val_loss: 7.7309 - lr: 3.9063e-06\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0075 - val_loss: 7.7331 - lr: 3.9063e-06\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.2297\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.2297 - val_loss: 7.7352 - lr: 3.9063e-06\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0621 - val_loss: 7.7393 - lr: 1.9531e-06\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9715 - val_loss: 7.7375 - lr: 1.9531e-06\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1564 - val_loss: 7.7347 - lr: 1.9531e-06\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0146 - val_loss: 7.7346 - lr: 1.9531e-06\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.9418\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9418 - val_loss: 7.7325 - lr: 1.9531e-06\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1280 - val_loss: 7.7326 - lr: 9.7656e-07\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0084 - val_loss: 7.7320 - lr: 9.7656e-07\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1377 - val_loss: 7.7315 - lr: 9.7656e-07\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.8939 - val_loss: 7.7305 - lr: 9.7656e-07\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0930\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0930 - val_loss: 7.7315 - lr: 9.7656e-07\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1145 - val_loss: 7.7315 - lr: 4.8828e-07\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0859 - val_loss: 7.7316 - lr: 4.8828e-07\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9830 - val_loss: 7.7309 - lr: 4.8828e-07\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9252 - val_loss: 7.7312 - lr: 4.8828e-07\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.9284\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9284 - val_loss: 7.7312 - lr: 4.8828e-07\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.9870 - val_loss: 7.7311 - lr: 2.4414e-07\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.0500 - val_loss: 7.7312 - lr: 2.4414e-07\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 1.8304 - val_loss: 7.7318 - lr: 2.4414e-07\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1209 - val_loss: 7.7320 - lr: 2.4414e-07\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0959\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 2.0959 - val_loss: 7.7317 - lr: 2.4414e-07\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 1.9388 - val_loss: 7.7320 - lr: 1.2207e-07\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 1.8892 - val_loss: 7.7323 - lr: 1.2207e-07\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 3s 113ms/step - loss: 2.0905 - val_loss: 7.7322 - lr: 1.2207e-07\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 4s 114ms/step - loss: 2.0570 - val_loss: 7.7321 - lr: 1.2207e-07\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.8966\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "31/31 [==============================] - 3s 113ms/step - loss: 1.8966 - val_loss: 7.7320 - lr: 1.2207e-07\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1704 - val_loss: 7.7320 - lr: 6.1035e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:09:13.879474: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1346520000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Set the input shape and number of classes (1 for regression)\n",
    "input_shape = (X_train.shape[1:])\n",
    "num_classes = 1\n",
    "\n",
    "# Create the model architecture\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "    return model\n",
    "\n",
    "# Initialize lists to store R2 scores for each fold\n",
    "r2_scores = []\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "num_folds = 3\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through cross-validation folds\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    # Split the data into train and validation sets for this fold\n",
    "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    # Create a new instance of the model for each fold\n",
    "    model = create_model()\n",
    "    lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)\n",
    "    # Train the model on the current fold's training data\n",
    "    model.fit(X_fold_train, y_fold_train, epochs=100, batch_size=32, validation_data=(X_fold_val, y_fold_val), callbacks=[lr_scheduler])\n",
    "    \n",
    "    # Evaluate the model on the current fold's validation data\n",
    "    y_fold_val_pred = model.predict(X_fold_val)\n",
    "    r2 = r2_score(y_fold_val, y_fold_val_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Calculate the mean and standard deviation of R2 scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3e496a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_r2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(r2_scores)\n\u001b[1;32m      2\u001b[0m std_r2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(r2_scores)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean R2 across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "print(f\"Mean R2 across {num_folds} folds: {mean_r2:.4f}\")\n",
    "print(f\"Standard Deviation of R2: {std_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ca464-689b-4919-9f0d-06ed9264ea60",
   "metadata": {},
   "source": [
    "model creation and building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fc4750-565f-454f-95ca-31a7b6ad23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 15:44:39.095438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.095643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.095784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.181336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.181470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.181579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-24 15:44:39.181658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1898] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10094 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-08-24 15:44:39.808802: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4036812000 exceeds 10% of free system memory.\n",
      "2023-08-24 15:44:42.565153: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4036812000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 15:44:44.584997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-08-24 15:44:45.949547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f361841d4e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-24 15:44:45.949565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-24 15:44:45.955360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-24 15:44:46.028852: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 11s 154ms/step - loss: 22.1182 - val_loss: 12.5629 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 13.7499 - val_loss: 11.4033 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 10.1893 - val_loss: 8.3092 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 9.6446 - val_loss: 8.8041 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 8.5449 - val_loss: 9.2243 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 7.3802 - val_loss: 8.6016 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 10.1476 - val_loss: 8.9323 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 9.1451 - val_loss: 7.8513 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 6.3679 - val_loss: 8.5504 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 5.7797 - val_loss: 8.9458 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 5.1074 - val_loss: 8.3598 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 4.6257 - val_loss: 9.0012 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 4.0430\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 4.0430 - val_loss: 8.6998 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 4.0151 - val_loss: 8.5537 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 3.4497 - val_loss: 9.1853 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 3.2841 - val_loss: 8.1534 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 3.1136 - val_loss: 8.0394 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 3.1543\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 3.1543 - val_loss: 8.0537 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.7869 - val_loss: 8.0343 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.7816 - val_loss: 8.1451 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.6889 - val_loss: 8.1523 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.9518 - val_loss: 8.0672 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 3.0073\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 3.0073 - val_loss: 8.0743 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.7283 - val_loss: 7.8546 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 2.3474 - val_loss: 7.9184 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 2.8747 - val_loss: 7.9087 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5712 - val_loss: 8.1909 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.8174\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.8174 - val_loss: 8.0829 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3351 - val_loss: 8.0348 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 2.4807 - val_loss: 7.9388 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 2.4512 - val_loss: 7.9846 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 2.8427 - val_loss: 8.3197 - lr: 6.2500e-05\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6125 - val_loss: 7.8303 - lr: 6.2500e-05\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6360 - val_loss: 7.8985 - lr: 6.2500e-05\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6301 - val_loss: 7.8937 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5323 - val_loss: 7.9935 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 2.7830 - val_loss: 7.8278 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6738 - val_loss: 7.8657 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.7026 - val_loss: 7.8928 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.2915 - val_loss: 7.9297 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3836 - val_loss: 7.9571 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.8245\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.8245 - val_loss: 7.9932 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4154 - val_loss: 7.8702 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5529 - val_loss: 7.9429 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4210 - val_loss: 7.8932 - lr: 3.1250e-05\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4798 - val_loss: 7.8560 - lr: 3.1250e-05\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.4064\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4064 - val_loss: 7.9472 - lr: 3.1250e-05\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3280 - val_loss: 7.8900 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5358 - val_loss: 7.9009 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5163 - val_loss: 7.8978 - lr: 1.5625e-05\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3480 - val_loss: 7.9220 - lr: 1.5625e-05\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.4606\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4606 - val_loss: 7.9264 - lr: 1.5625e-05\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4541 - val_loss: 7.9067 - lr: 7.8125e-06\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3643 - val_loss: 7.9078 - lr: 7.8125e-06\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3246 - val_loss: 7.9225 - lr: 7.8125e-06\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4350 - val_loss: 7.9216 - lr: 7.8125e-06\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.3164\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3164 - val_loss: 7.9034 - lr: 7.8125e-06\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.4700 - val_loss: 7.9231 - lr: 3.9063e-06\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3418 - val_loss: 7.9044 - lr: 3.9063e-06\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4735 - val_loss: 7.8963 - lr: 3.9063e-06\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 4s 97ms/step - loss: 2.2267 - val_loss: 7.8950 - lr: 3.9063e-06\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.5119\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5119 - val_loss: 7.9280 - lr: 3.9063e-06\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4161 - val_loss: 7.9187 - lr: 1.9531e-06\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 2.6452 - val_loss: 7.9081 - lr: 1.9531e-06\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6085 - val_loss: 7.9138 - lr: 1.9531e-06\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.1673 - val_loss: 7.9120 - lr: 1.9531e-06\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.4822\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.4822 - val_loss: 7.9164 - lr: 1.9531e-06\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.3209 - val_loss: 7.9223 - lr: 9.7656e-07\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5026 - val_loss: 7.9223 - lr: 9.7656e-07\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.3623 - val_loss: 7.9183 - lr: 9.7656e-07\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.4903 - val_loss: 7.9144 - lr: 9.7656e-07\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.3773\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3773 - val_loss: 7.9061 - lr: 9.7656e-07\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.2107 - val_loss: 7.9063 - lr: 4.8828e-07\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.6534 - val_loss: 7.9042 - lr: 4.8828e-07\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3119 - val_loss: 7.9033 - lr: 4.8828e-07\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5493 - val_loss: 7.9025 - lr: 4.8828e-07\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.4524\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4524 - val_loss: 7.9047 - lr: 4.8828e-07\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.2807 - val_loss: 7.9044 - lr: 2.4414e-07\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.2879 - val_loss: 7.9053 - lr: 2.4414e-07\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3808 - val_loss: 7.9046 - lr: 2.4414e-07\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3529 - val_loss: 7.9046 - lr: 2.4414e-07\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.4485\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 2.4485 - val_loss: 7.9041 - lr: 2.4414e-07\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.2990 - val_loss: 7.9040 - lr: 1.2207e-07\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 2.4145 - val_loss: 7.9047 - lr: 1.2207e-07\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5159 - val_loss: 7.9047 - lr: 1.2207e-07\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3007 - val_loss: 7.9047 - lr: 1.2207e-07\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.3589\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3589 - val_loss: 7.9050 - lr: 1.2207e-07\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.7033 - val_loss: 7.9050 - lr: 6.1035e-08\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3275 - val_loss: 7.9051 - lr: 6.1035e-08\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5516 - val_loss: 7.9051 - lr: 6.1035e-08\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4225 - val_loss: 7.9051 - lr: 6.1035e-08\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.3013\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 2.3013 - val_loss: 7.9048 - lr: 6.1035e-08\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.3793 - val_loss: 7.9049 - lr: 3.0518e-08\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3506 - val_loss: 7.9049 - lr: 3.0518e-08\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.5793 - val_loss: 7.9048 - lr: 3.0518e-08\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5458 - val_loss: 7.9048 - lr: 3.0518e-08\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - ETA: 0s - loss: 2.5556\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.5556 - val_loss: 7.9047 - lr: 3.0518e-08\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 2.3854 - val_loss: 7.9047 - lr: 1.5259e-08\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.4882 - val_loss: 7.9047 - lr: 1.5259e-08\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 2.3271 - val_loss: 7.9047 - lr: 1.5259e-08\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape and number of classes (1 for regression)\n",
    "input_shape = (X_train.shape[1:])\n",
    "num_classes = 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='linear'))  # Using 'linear' activation for regression\n",
    "\n",
    "# Compile the model with appropriate loss function and optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "# Apply learning rate scheduling\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# Train the model using the training dataset and validate on the validation set\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a0ce2-1a5e-4505-b69d-96e3bc10dfef",
   "metadata": {},
   "source": [
    "checking the mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6002df0a-663e-4a27-8217-175146ca5cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 15:52:23.827047: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1162404000 exceeds 10% of free system memory.\n",
      "2023-08-24 15:52:24.703923: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1162404000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 38ms/step\n",
      "Mean Squared Error (MSE): 3.0743160628446993\n",
      "R-squared Score: 0.7987661475012363\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have predictions and true values as numpy arrays\n",
    "prediction = model.predict(X_test)\n",
    "y_true = np.array(y_test)  # True delta_G values for the test data\n",
    "y_pred = prediction.reshape(-1)  # Reshape predictions to a 1D array if needed\n",
    "\n",
    "# Calculate mean squared error (MSE)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Calculate coefficient of determination (R-squared score)\n",
    "r2_score_value = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared Score:\", r2_score_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf157c2-5a64-4c0e-a77c-c59f1027a8e8",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96393919-9ac3-43f4-9a25-6a0462a5474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('change_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0cd52-9de7-4655-bace-3c9be794adda",
   "metadata": {},
   "source": [
    "for predicting Delta_G  of single sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccff7a1-aa4e-43eb-8063-e40c8178d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Protein sequence for prediction\n",
    "protein_sequence = 'MIPLLGNSRETCGSDRGGFNKFGGPRDQGSRHDSEQDNSDNNTIFVQGLGENVTIESVADYFKQIGIIKTNKKTGQPMINLYTDRETGKLKGEATVSFDDPPSAKAAIDWFDGMYEKAGRGKEFSGNPIKVSFATRRADFNRGGGNGRGGRGRGGPMGRGGYGGGGSGGGGRGGFPSGGGGGGGQQRAGDWKCPNPTCENMNFSWRNECNQCKAPKPDGPGGGPGGSHMGGNYGDDRRGGRGGYDRGGYRGRGGDRGGFRGGRGGGDRGGFGPGKMDSRGEHRQDRRERPY'\n",
    "# Load the model\n",
    "model = load_model('/home/gdt-ws4/Desktop/prediction_all/change_data.h5')\n",
    "# Define the amino acids and their order\n",
    "\n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    # Create a dictionary to map each amino acid to an index\n",
    "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "    \n",
    "    # Initialize an array of zeros with the shape (sequence_length, number_of_amino_acids)\n",
    "    sequence_length = len(sequence)\n",
    "    one_hot_encoded = np.zeros((sequence_length, len(amino_acids)), dtype=int)\n",
    "    \n",
    "    # Set the appropriate index to 1 for each amino acid in the sequence\n",
    "    for i, aa in enumerate(sequence):\n",
    "        one_hot_encoded[i, aa_to_index[aa]] = 1\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "# One-hot encode the protein sequence\n",
    "encoded_sequence = one_hot_encode_sequence(protein_sequence)\n",
    "\n",
    "# Pad the sequence to the desired length (34350)\n",
    "desired_sequence_length = 34350\n",
    "padded_encoded_sequence = np.pad(encoded_sequence, ((0, desired_sequence_length - len(encoded_sequence)), (0, 0)), 'constant')\n",
    "\n",
    "# Reshape to a 3D array with shape (1, 34350, 20)\n",
    "encoded_sequence_3D = padded_encoded_sequence[np.newaxis, :, :]\n",
    "\n",
    "# Make predictions using the model\n",
    "predicted_delta_g = model.predict(encoded_sequence_3D)\n",
    "\n",
    "print(\"Predicted Delta_G value:\", predicted_delta_g[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted Delta_G value: 6.130406\n",
    "Predicted Delta_G value: 4.6328096"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c59fff-2cd1-435b-b05c-ce9f1d61846a",
   "metadata": {},
   "source": [
    "predicting all sequence in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb87ee-7b5f-40ae-9efb-19e78d90c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is the DataFrame containing all the columns as described\n",
    "X_test = df['Mutated Sequence']\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_sequence_length = 34350\n",
    "\n",
    "# Assuming one_hot_encode_sequence function is defined as before\n",
    "\n",
    "# Pad or truncate the sequences to the maximum length\n",
    "encoded_sequences = [one_hot_encode_sequence(seq) for seq in X_test]\n",
    "padded_sequences = pad_sequences(encoded_sequences, maxlen=max_sequence_length, padding='post', dtype='float32')\n",
    "\n",
    "# Load the trained model from the file\n",
    "model = load_model('change_data.h5')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predicted_delta_g = model.predict(padded_sequences)\n",
    "\n",
    "# Create a new DataFrame with all the columns and Predicted Delta_G values\n",
    "df_predicted = pd.DataFrame({\n",
    "    'Main': df['Main'],\n",
    "    'Swiss-Prot': df['Swiss-Prot'],\n",
    "    'AA': df['AA'],\n",
    "    'Variant': df['Variant'],\n",
    "    'FTId': df['FTId'],\n",
    "    'dbSNP': df['dbSNP'],\n",
    "    'Disease name': df['Disease name'],\n",
    "    'new_variant': df['new_variant'],\n",
    "    'sequences_data': df['sequences_data'],\n",
    "    'Mutated Sequence': X_test,\n",
    "    'Delta_G': predicted_delta_g.flatten()\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afda43-5662-4c4e-82a2-8041fc773aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
